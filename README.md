## Transformer

논문 링크: [Transformer](https://arxiv.org/abs/1706.03762)

Transformer는 자연어 처리 분야에 있어 혁명을 불러일으킨 모델로, CNN이나 RNN을 사용하지 않고 오로지 Attention mechanism만을 사용했다는 특징을 가지고 있다. Transformer의 구조는 다음과 같다.

<img src="https://github.com/mathdoyun/Transformer/assets/135238974/6b268b85-7fa9-4c41-9ea7-5015fc17ddb6" width="50%" height="50%"/>

구조가 복잡하지만 하나씩 차근차근 보니 이해할 수 있었고, 직접 코드를 작성하며 실습해보니 그 구조를 더 명확하게 파악할 수 있었다.

> 출처: https://www.youtube.com/watch?v=AA621UofTUA&t=2622s

---

P.S. 원래 코드는 왜인지 모르겠지만 Multi30k dataset을 불러오는 데 문제가 발생해서 데이터셋을 받는 부분의 코드를 수정했다.
